{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LayeredNetwork.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0e5ba806a80b42cc81ba7a167b98f70b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_48092280ac294a699332988b37cfa493","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b2a0a3917ff4c73b170a48de8de6e77","IPY_MODEL_b339c29438024b0ebeaf371bbe162a02"]}},"48092280ac294a699332988b37cfa493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b2a0a3917ff4c73b170a48de8de6e77":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a8ef8b3bd90e4b9ab89bbb14c29448fa","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec1d886c19b6470d8f9628fad902f9ec"}},"b339c29438024b0ebeaf371bbe162a02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67ec3246c965433d97c36a22d7fe80d4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:03&lt;00:00, 3031072.16it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c45c88f716c4f968d410f1fc854e5b6"}},"a8ef8b3bd90e4b9ab89bbb14c29448fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec1d886c19b6470d8f9628fad902f9ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67ec3246c965433d97c36a22d7fe80d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c45c88f716c4f968d410f1fc854e5b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9f34187b86b4bcdae3590386b22a53d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e64c2299efb84ba8996a90d87486db73","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_70213858aa71493fb8996074997ad7ea","IPY_MODEL_9c517317de0741b4be8b444d1c578d47"]}},"e64c2299efb84ba8996a90d87486db73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70213858aa71493fb8996074997ad7ea":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_62a7c6c984cf4ba996d189fbcb536867","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8631ffb0c0d24dd8b240564813db5641"}},"9c517317de0741b4be8b444d1c578d47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a266c2c1e46e4aab9e564004a68ff531","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:01&lt;00:00, 16813.06it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f95003b9554c4d6bbbba3c75acf803ad"}},"62a7c6c984cf4ba996d189fbcb536867":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8631ffb0c0d24dd8b240564813db5641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a266c2c1e46e4aab9e564004a68ff531":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f95003b9554c4d6bbbba3c75acf803ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4ce5b96190b4a6c8fc4c7e74e5e50cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3aa42773d4fb4521a169010ab04addaa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2ac005f26b1e4552bd4d74316e8a0af3","IPY_MODEL_118da72e2ddd4ff3aaa6352d1b024ffb"]}},"3aa42773d4fb4521a169010ab04addaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ac005f26b1e4552bd4d74316e8a0af3":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9302c8a3e1cf4e51b4d8d979734ca00b","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d4440bc4bc8443aa55339601cf2696f"}},"118da72e2ddd4ff3aaa6352d1b024ffb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b364f11300b1439e9cdee62b352c9da6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:01&lt;00:00, 1547260.51it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1cfd02e9a0e74ffea78db89cd8c94d1b"}},"9302c8a3e1cf4e51b4d8d979734ca00b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d4440bc4bc8443aa55339601cf2696f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b364f11300b1439e9cdee62b352c9da6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1cfd02e9a0e74ffea78db89cd8c94d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ef28e789abd4996ad12681bfb778615":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cd8134c2d0934547ad3f5b8079851c48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c31d463b988a4de9b36c07c6a7a99c84","IPY_MODEL_c08bdaa85964475e810f83c9871002b1"]}},"cd8134c2d0934547ad3f5b8079851c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c31d463b988a4de9b36c07c6a7a99c84":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f9be2f69f91d4a8ab083ae26c30ec045","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cebc8a44f5864bafa27186905ed12699"}},"c08bdaa85964475e810f83c9871002b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_548952323aa846328b573099d113ac4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:00&lt;00:00, 22500.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e37a916c1d436694635e478ed1394b"}},"f9be2f69f91d4a8ab083ae26c30ec045":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cebc8a44f5864bafa27186905ed12699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"548952323aa846328b573099d113ac4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97e37a916c1d436694635e478ed1394b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UFDCDlDW16pv","colab_type":"text"},"source":["Downloading the MNIST data and filtering specific digits to train"]},{"cell_type":"code","metadata":{"id":"l0dIHmvxulL0","colab_type":"code","outputId":"1f77f16a-a8a2-400e-b37b-b6201d11cd1c","executionInfo":{"status":"ok","timestamp":1586838608952,"user_tz":240,"elapsed":16029,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":383,"referenced_widgets":["0e5ba806a80b42cc81ba7a167b98f70b","48092280ac294a699332988b37cfa493","8b2a0a3917ff4c73b170a48de8de6e77","b339c29438024b0ebeaf371bbe162a02","a8ef8b3bd90e4b9ab89bbb14c29448fa","ec1d886c19b6470d8f9628fad902f9ec","67ec3246c965433d97c36a22d7fe80d4","3c45c88f716c4f968d410f1fc854e5b6","e9f34187b86b4bcdae3590386b22a53d","e64c2299efb84ba8996a90d87486db73","70213858aa71493fb8996074997ad7ea","9c517317de0741b4be8b444d1c578d47","62a7c6c984cf4ba996d189fbcb536867","8631ffb0c0d24dd8b240564813db5641","a266c2c1e46e4aab9e564004a68ff531","f95003b9554c4d6bbbba3c75acf803ad","c4ce5b96190b4a6c8fc4c7e74e5e50cc","3aa42773d4fb4521a169010ab04addaa","2ac005f26b1e4552bd4d74316e8a0af3","118da72e2ddd4ff3aaa6352d1b024ffb","9302c8a3e1cf4e51b4d8d979734ca00b","5d4440bc4bc8443aa55339601cf2696f","b364f11300b1439e9cdee62b352c9da6","1cfd02e9a0e74ffea78db89cd8c94d1b","5ef28e789abd4996ad12681bfb778615","cd8134c2d0934547ad3f5b8079851c48","c31d463b988a4de9b36c07c6a7a99c84","c08bdaa85964475e810f83c9871002b1","f9be2f69f91d4a8ab083ae26c30ec045","cebc8a44f5864bafa27186905ed12699","548952323aa846328b573099d113ac4d","97e37a916c1d436694635e478ed1394b"]}},"source":["from random import randrange\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","from numba import jitclass,jit,njit, cuda \n","\n","batch_size=200\n","criterion = nn.NLLLoss()\n","use_cuda = True\n","\n","#To transform the MNIST data into tensor datatype and normalize the values\n","transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])\n","\n","#Download the training data and apply the above transformations\n","mnist1 = datasets.MNIST('../data', train=True, download=True, transform = transform)\n","\n","#Filter the training images with just '0' and '1' digits\n","filtered_train = []\n","for data in enumerate(mnist1):\n","    if(data[1][1] == 1 or data[1][1] == 0):\n","        filtered_train.append(list(data[1]))\n","\n","#Similarly storing the testing data with digits '0' and '1' in filtered_test\n","mnist = datasets.MNIST('../data', train=False, transform=transform)\n","\n","filtered_test = []\n","for data in enumerate(mnist):\n","    if(data[1][1] == 1 or data[1][1] == 0):\n","        # print((data[0],data[1]))\n","        filtered_test.append(list(data[1]))\n","\n","#Readjusting the data to a size of multiple of 'batch_size' by slicing\n","filtered_train = filtered_train[0:-(len(filtered_train)%batch_size)]\n","filtered_test = filtered_test[0:-(len(filtered_test)%batch_size)]\n","\n","# filtered_train = mnist1\n","# filtered_test = mnist\n","\n","#storing the filtered data in the torch's dataLoader with batch size and shuffle capabilities\n","#The data loader provides easier management of the data with automatic facilities like shuffling data and dividing it into batches.\n","train_loader = torch.utils.data.DataLoader(\n","    filtered_train,\n","    batch_size=batch_size, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    filtered_test,\n","    batch_size=batch_size, shuffle=True)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e5ba806a80b42cc81ba7a167b98f70b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9f34187b86b4bcdae3590386b22a53d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4ce5b96190b4a6c8fc4c7e74e5e50cc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ef28e789abd4996ad12681bfb778615","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","Processing...\n","Done!\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0H5ediXs6YMI","colab_type":"text"},"source":["# Creating the fully connected sub network\n","\n","Once trained, this network will take in input image of size 28X28 and give an output through a 10 nodes output layer representing the digit in the image."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3E4qezhYKdwS","outputId":"05afb58b-bd94-45b6-9066-697008b4a4b4","executionInfo":{"status":"ok","timestamp":1586838619705,"user_tz":240,"elapsed":26772,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def create_subnet(learning_rate=0.01, epochs=10,\n","              log_interval=10):\n","    #Inheriting nn.Module class of PyTorch\n","    class SubNet(nn.Module):\n","        #Defining the network architecture of 4 fully connected layers, input and output layer inclusive\n","        #Layer 1 size = 784 (for 28X28 image)\n","        #Layer 2 size = 200\n","        #Layer 3 size = 200\n","        #Layer 4 size = 10 (representing the output digit 0 to 9)\n","        def __init__(self):\n","            super(SubNet, self).__init__()\n","            self.fc1 = nn.Linear(28 * 28, 200)\n","            self.fc2 = nn.Linear(200, 200)\n","            self.fc3 = nn.Linear(200, 10)\n","\n","        #The output of every hidden layer is subject to the relu function as configured in the forward method below\n","        #The final output is subject to log_softmax function as a way to normalize our output\n","        def forward(self, x):\n","            x = F.relu(self.fc1(x))\n","            x = F.relu(self.fc2(x))\n","            x = self.fc3(x)\n","            return F.log_softmax(x)\n","\n","    #The subnet is stored in a variable for later use in the composite network\n","    subnet = SubNet()\n","    print(subnet)\n","\n","    #This is to enable GPU processing of our program for enhanced performance speed\n","    if use_cuda and torch.cuda.is_available():\n","        subnet.cuda()\n","\n","    #This is a stochastic gradient descent optimizer\n","    optimizer = optim.SGD(subnet.parameters(), lr=learning_rate, momentum=0.9)\n","\n","    # run the main training loop\n","    for epoch in range(epochs):\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            data, target = Variable(data), Variable(target)\n","            # resshape data from (batch_size, 1, 28, 28) to (batch_size, 28*28), because the fully connected input layer is one dimensional\n","            data = data.view(-1,28*28)\n","            if use_cuda and torch.cuda.is_available():\n","                data = data.cuda()\n","                target = target.cuda()\n","            \n","            #This zeroes / resets all the gradients in the model, so that it is ready to go for the next back propagation pass\n","            optimizer.zero_grad()\n","            subnet_out = subnet(data)\n","\n","            #This set of statements runs the backpropogation based on the loss and gradient calculated\n","            loss = criterion(subnet_out, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch_idx % log_interval == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, batch_idx * len(data), len(train_loader.dataset),\n","                           100. * batch_idx / len(train_loader), loss.data))\n","    return subnet\n","\n","\n","if __name__ == \"__main__\":\n","      subnet = create_subnet()\n","      # test_nn()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["SubNet(\n","  (fc1): Linear(in_features=784, out_features=200, bias=True)\n","  (fc2): Linear(in_features=200, out_features=200, bias=True)\n","  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 0 [0/12600 (0%)]\tLoss: 2.340443\n","Train Epoch: 0 [2000/12600 (16%)]\tLoss: 0.402350\n","Train Epoch: 0 [4000/12600 (32%)]\tLoss: 0.013506\n","Train Epoch: 0 [6000/12600 (48%)]\tLoss: 0.000326\n","Train Epoch: 0 [8000/12600 (63%)]\tLoss: 0.005212\n","Train Epoch: 0 [10000/12600 (79%)]\tLoss: 0.012542\n","Train Epoch: 0 [12000/12600 (95%)]\tLoss: 0.036249\n","Train Epoch: 1 [0/12600 (0%)]\tLoss: 0.000900\n","Train Epoch: 1 [2000/12600 (16%)]\tLoss: 0.000096\n","Train Epoch: 1 [4000/12600 (32%)]\tLoss: 0.000218\n","Train Epoch: 1 [6000/12600 (48%)]\tLoss: 0.034936\n","Train Epoch: 1 [8000/12600 (63%)]\tLoss: 0.001150\n","Train Epoch: 1 [10000/12600 (79%)]\tLoss: 0.001502\n","Train Epoch: 1 [12000/12600 (95%)]\tLoss: 0.000102\n","Train Epoch: 2 [0/12600 (0%)]\tLoss: 0.005235\n","Train Epoch: 2 [2000/12600 (16%)]\tLoss: 0.023179\n","Train Epoch: 2 [4000/12600 (32%)]\tLoss: 0.015462\n","Train Epoch: 2 [6000/12600 (48%)]\tLoss: 0.035783\n","Train Epoch: 2 [8000/12600 (63%)]\tLoss: 0.001379\n","Train Epoch: 2 [10000/12600 (79%)]\tLoss: 0.001247\n","Train Epoch: 2 [12000/12600 (95%)]\tLoss: 0.000321\n","Train Epoch: 3 [0/12600 (0%)]\tLoss: 0.000054\n","Train Epoch: 3 [2000/12600 (16%)]\tLoss: 0.001686\n","Train Epoch: 3 [4000/12600 (32%)]\tLoss: 0.002704\n","Train Epoch: 3 [6000/12600 (48%)]\tLoss: 0.000370\n","Train Epoch: 3 [8000/12600 (63%)]\tLoss: 0.001300\n","Train Epoch: 3 [10000/12600 (79%)]\tLoss: 0.000109\n","Train Epoch: 3 [12000/12600 (95%)]\tLoss: 0.013704\n","Train Epoch: 4 [0/12600 (0%)]\tLoss: 0.001014\n","Train Epoch: 4 [2000/12600 (16%)]\tLoss: 0.013418\n","Train Epoch: 4 [4000/12600 (32%)]\tLoss: 0.000453\n","Train Epoch: 4 [6000/12600 (48%)]\tLoss: 0.000099\n","Train Epoch: 4 [8000/12600 (63%)]\tLoss: 0.000137\n","Train Epoch: 4 [10000/12600 (79%)]\tLoss: 0.002347\n","Train Epoch: 4 [12000/12600 (95%)]\tLoss: 0.013113\n","Train Epoch: 5 [0/12600 (0%)]\tLoss: 0.000878\n","Train Epoch: 5 [2000/12600 (16%)]\tLoss: 0.000396\n","Train Epoch: 5 [4000/12600 (32%)]\tLoss: 0.002556\n","Train Epoch: 5 [6000/12600 (48%)]\tLoss: 0.004531\n","Train Epoch: 5 [8000/12600 (63%)]\tLoss: 0.000534\n","Train Epoch: 5 [10000/12600 (79%)]\tLoss: 0.004763\n","Train Epoch: 5 [12000/12600 (95%)]\tLoss: 0.000180\n","Train Epoch: 6 [0/12600 (0%)]\tLoss: 0.003089\n","Train Epoch: 6 [2000/12600 (16%)]\tLoss: 0.000063\n","Train Epoch: 6 [4000/12600 (32%)]\tLoss: 0.000242\n","Train Epoch: 6 [6000/12600 (48%)]\tLoss: 0.000162\n","Train Epoch: 6 [8000/12600 (63%)]\tLoss: 0.000451\n","Train Epoch: 6 [10000/12600 (79%)]\tLoss: 0.000117\n","Train Epoch: 6 [12000/12600 (95%)]\tLoss: 0.012487\n","Train Epoch: 7 [0/12600 (0%)]\tLoss: 0.000124\n","Train Epoch: 7 [2000/12600 (16%)]\tLoss: 0.009571\n","Train Epoch: 7 [4000/12600 (32%)]\tLoss: 0.005608\n","Train Epoch: 7 [6000/12600 (48%)]\tLoss: 0.000124\n","Train Epoch: 7 [8000/12600 (63%)]\tLoss: 0.000826\n","Train Epoch: 7 [10000/12600 (79%)]\tLoss: 0.002609\n","Train Epoch: 7 [12000/12600 (95%)]\tLoss: 0.000107\n","Train Epoch: 8 [0/12600 (0%)]\tLoss: 0.000468\n","Train Epoch: 8 [2000/12600 (16%)]\tLoss: 0.000311\n","Train Epoch: 8 [4000/12600 (32%)]\tLoss: 0.000121\n","Train Epoch: 8 [6000/12600 (48%)]\tLoss: 0.000080\n","Train Epoch: 8 [8000/12600 (63%)]\tLoss: 0.000194\n","Train Epoch: 8 [10000/12600 (79%)]\tLoss: 0.000592\n","Train Epoch: 8 [12000/12600 (95%)]\tLoss: 0.000120\n","Train Epoch: 9 [0/12600 (0%)]\tLoss: 0.001412\n","Train Epoch: 9 [2000/12600 (16%)]\tLoss: 0.000995\n","Train Epoch: 9 [4000/12600 (32%)]\tLoss: 0.001735\n","Train Epoch: 9 [6000/12600 (48%)]\tLoss: 0.000056\n","Train Epoch: 9 [8000/12600 (63%)]\tLoss: 0.000389\n","Train Epoch: 9 [10000/12600 (79%)]\tLoss: 0.000117\n","Train Epoch: 9 [12000/12600 (95%)]\tLoss: 0.001284\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LFlqJ_UbnHdW","colab_type":"text"},"source":["Use this block to test the accuracy of subnet"]},{"cell_type":"code","metadata":{"id":"Y4V8wAv9FXTw","colab_type":"code","outputId":"3641453c-b9c1-4277-e44e-700c69c3e387","executionInfo":{"status":"ok","timestamp":1586838619707,"user_tz":240,"elapsed":26758,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["def test_nn():\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        data, target = Variable(data, volatile=True), Variable(target)\n","        data = data.view(-1,28*28)\n","\n","        if use_cuda and torch.cuda.is_available():\n","            data = data.cuda()\n","            target = target.cuda()\n","        subnet_out = subnet(data)\n","        # sum up batch loss\n","        test_loss += criterion(subnet_out, target).data\n","        pred = subnet_out.data.max(1)[1]  # get the index of the max log-probability\n","        correct += pred.eq(target.data).sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","test_nn()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set: Average loss: 0.0000, Accuracy: 1999/2000 (100%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"P21XAQpyoDVh","colab_type":"text"},"source":["#The Composite network\n","\n","This network aims at using the subnet's capabilities and train itself according to the output format of subnet in order to find the 28X28 size digits on a 56X56 input image.\n","\n","This basically will be a convolution mechanism in which instead of a regular filter, we shall use the subnet. i.e., instead of associating weights with a regular 28X28 sized filter, as is the case in convolution, here we are mapping the 28X28 filter with the subnet.\n","\n","And as we get the output value from a normal filter by taking the sum of all the activation values multiplied by their corresponding weights, here the output is the result of whatever value is given by the subnet.\n","\n","The output channel is again input into the next hidden layer of the network.\n","\n","##Data Augmentation\n","Another aspect of the following network is the data augmentation part where we create the 56X56 input image.\n","For this we use the 28X28 image and add it to an array of zeroes of size 56X56. For details refer to \"Shuffle\" method."]},{"cell_type":"code","metadata":{"id":"FIhjGrDI40pY","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import time\n","from numba import jit,njit, cuda \n","import tensorflow as tf\n","from google.colab import files\n","\n","# rndx and rndy determine the position of the 28X28 'image' in the 56X56 grid(here stored in 'a')\n","def shuffle(rndx,rndy,image):\n","    a = np.zeros((56,56))\n","    image = image.view(-1, 28)\n","    # Adding the 'image' to the part of 'a' sliced from 'rndx', 'rndy'\n","    a[rndx:28+rndx,rndy:28+rndy]+=np.array(image)\n","    return torch.as_tensor(a).float()\n","\n","# this method performs the custom convolution using the 'subnet' over the input batch 'img_batch' of 56X56 size images\n","def custom_conv(img_batch):\n","    # this is also the shape of 'img_batch', except 56X56 image size\n","    ret = torch.zeros([batch_size,1,28,28], dtype=torch.float)\n","    print('A',time.process_time())\n","    temp1 = torch.zeros([784])\n","    temp4 = torch.zeros([784])\n","    maxValues = torch.zeros([784])\n","    minValues = torch.zeros([784])\n","    for b in range(batch_size):\n","        img = img_batch[b]\n","        input_to_subnet = torch.zeros([0,28*28], dtype=torch.float)\n","        if use_cuda and torch.cuda.is_available():\n","            input_to_subnet = input_to_subnet.cuda()\n","        # plt.imshow(img)\n","        # plt.show()\n","        # print('I',time.process_time())\n","        # Iterations simulate the convolution over the 56X56 'img'\n","        for x in range(0,28):\n","            for y in range(0,28):\n","                input1 = torch.Tensor([784])\n","                # slicing out the 'input' from 'img' at location x,y to x+28,y+28\n","                input1=img[x:x+28, y:y+28].reshape(-1,28*28)\n","                input_to_subnet = torch.cat((input_to_subnet, input1), 0)\n","        # Sending the 'input' to subnet to get an output number which will act as activation value for the resulting channel at location 'x', 'y'\n","        subnet_result=subnet(input_to_subnet)\n","        # maxIndeces = torch.max(subnet_result, dim=1)[0]\n","        maxValues = torch.max(subnet_result, dim=1)[1]\n","        # minValues = torch.min(subnet_result, dim=1)[0]\n","        # confidenceValues = torch.sub(maxIndeces, 1, minValues)\n","        ret[b,0] = maxValues.view(28,28)\n","        # ret[b,1] = temp4.view(28,28)\n","    return ret\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5mSYrOFXGfMy","colab_type":"text"},"source":["In this section we use the above 2 utility methods to actually transform the data and store it into files for training of the second network and the composite network"]},{"cell_type":"code","metadata":{"id":"4JQ1FrSANLQ-","colab_type":"code","outputId":"7a31f2ae-454b-421f-a183-f49582dd6714","executionInfo":{"status":"ok","timestamp":1586838632228,"user_tz":240,"elapsed":39261,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=1d930b36af24322f74b0d29b1247844f000e7cf605f112dbd7a6b96cd05d4275\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 11.0 GB  |     Proc size: 2.9 GB\n","GPU RAM Free: 15555MB | Used: 725MB | Util   4% | Total     16280MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIsZ5ch7GZSY","colab_type":"code","outputId":"0df50ff7-7f8d-4c34-ceea-0dfdbba91f55","executionInfo":{"status":"ok","timestamp":1586839232768,"user_tz":240,"elapsed":639792,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["filtered_train_shuffled = []\n","filtered_test_shuffled = []\n","for data in enumerate(filtered_train):\n","    # Use shuffle method for data augmentation of each image in the batch\n","    # temp = torch.as_tensor(np.zeros((200, 1, 28*2, 28*2))).float()\n","    image = data[1][0]\n","    # print(data)\n","    rndx = randrange(29)\n","    rndy = randrange(29)\n","    temp2 = list(data[1])\n","    temp2[0] = shuffle(rndx,rndy,image)\n","    filtered_train_shuffled.append(temp2)\n","for data in enumerate(filtered_test):\n","    # Use shuffle method for data augmentation of each image in the batch\n","    # temp = torch.as_tensor(np.zeros((200, 1, 28*2, 28*2))).float()\n","    image = data[1][0]\n","    rndx = randrange(29)\n","    rndy = randrange(29)\n","    temp2 = list(data[1])\n","    temp2[0] = shuffle(rndx,rndy,image)\n","    filtered_test_shuffled.append(temp2)\n","\n","\n","train_loader_shuffled = torch.utils.data.DataLoader(\n","    filtered_train_shuffled,\n","    batch_size=batch_size, shuffle=False)\n","\n","test_loader_shuffled = torch.utils.data.DataLoader(\n","    filtered_test_shuffled,\n","    batch_size=batch_size, shuffle=False)\n","\n","#these datatypes will go into our file storage and be used for training of the subsequent network\n","final_out = torch.zeros([0,1,28,28], dtype=torch.float)\n","final_out_targets = torch.zeros([0])\n","final_test = torch.zeros([0,1,28,28], dtype=torch.float)\n","final_test_tagerts = torch.zeros([0])\n","if use_cuda and torch.cuda.is_available():\n","    final_out = final_out.cuda()\n","    final_out_targets = final_out_targets.cuda()\n","    final_test = final_out.cuda()\n","    final_test_tagerts = final_out_targets.cuda()\n","\n","\n","for batch_idx, (data, target) in enumerate(train_loader_shuffled):\n","    data, target = Variable(data), Variable(target)\n","\n","    if use_cuda and torch.cuda.is_available():\n","        data = data.cuda()\n","        target = target.cuda()\n","    \n","    out = custom_conv(data)\n","    \n","    if use_cuda and torch.cuda.is_available():\n","        out = out.cuda()\n","    \n","    final_out = torch.cat((final_out, out), 0)\n","    final_out_targets = torch.cat((final_out_targets, target.float()), 0)\n","\n","    if batch_idx % 10 == 0:\n","        print('Train Epoch: [{}/{} ({:.0f}%)]'.format(\n","            batch_idx * len(data), len(train_loader_shuffled.dataset),\n","                    100. * batch_idx / len(train_loader_shuffled)))\n","\n","torch.save(final_out, 'file2.pt')\n","torch.save(final_out_targets, 'file_label.pt')\n","# files.download('file.pt') \n","\n","for batch_idx, (data, target) in enumerate(test_loader_shuffled):\n","    data, target = Variable(data), Variable(target)\n","\n","    if use_cuda and torch.cuda.is_available():\n","        data = data.cuda()\n","        target = target.cuda()\n","\n","    out = custom_conv(data)\n","\n","    if use_cuda and torch.cuda.is_available():\n","        out = out.cuda()\n","\n","    final_test = torch.cat((final_test, out), 0)\n","    final_test_tagerts = torch.cat((final_test_tagerts, target.float()), 0)\n","\n","    if batch_idx % 10 == 0:\n","        print('Test Epoch: [{}/{} ({:.0f}%)]'.format(\n","            batch_idx * len(data), len(test_loader_shuffled.dataset),\n","                    100. * batch_idx / len(test_loader_shuffled)))\n","torch.save(final_test, 'test.pt')\n","torch.save(final_test_tagerts, 'test_label.pt')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A 17.930486571\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: [0/12600 (0%)]\n","A 25.9878687\n","A 34.091239434\n","A 42.180698448\n","A 50.372845513\n","A 58.529622386\n","A 66.587116293\n","A 74.61342797\n","A 82.762778364\n","A 90.77949876\n","A 98.771201544\n","Train Epoch: [2000/12600 (16%)]\n","A 106.800886303\n","A 114.826538139\n","A 122.867978631\n","A 131.052582963\n","A 139.106684842\n","A 147.034316438\n","A 155.338448892\n","A 163.617744719\n","A 171.864978093\n","A 179.945844973\n","Train Epoch: [4000/12600 (32%)]\n","A 188.008660423\n","A 196.146197604\n","A 204.298708511\n","A 212.32478403\n","A 220.319362493\n","A 228.388111344\n","A 236.450456794\n","A 244.430572496\n","A 252.401122972\n","A 260.456004492\n","Train Epoch: [6000/12600 (48%)]\n","A 268.752336865\n","A 276.860299993\n","A 285.079153741\n","A 293.184142307\n","A 301.340296817\n","A 309.298193962\n","A 317.418153703\n","A 325.532712912\n","A 333.634001835\n","A 341.779341658\n","Train Epoch: [8000/12600 (63%)]\n","A 349.876676523\n","A 358.087650036\n","A 366.212108047\n","A 374.227717113\n","A 382.339863508\n","A 390.311140054\n","A 398.334308769\n","A 406.278812288\n","A 414.337263481\n","A 422.377202221\n","Train Epoch: [10000/12600 (79%)]\n","A 430.39271239\n","A 438.458679297\n","A 446.581274481\n","A 454.769161498\n","A 462.934698313\n","A 471.052766651\n","A 479.124717318\n","A 487.217183327\n","A 495.379265012\n","A 503.547490084\n","Train Epoch: [12000/12600 (95%)]\n","A 511.708094133\n","A 519.857099977\n","A 528.135159906\n","Test Epoch: [0/2000 (0%)]\n","A 536.407121787\n","A 544.687077908\n","A 552.877960738\n","A 561.035956886\n","A 569.283393306\n","A 577.561789737\n","A 585.822746102\n","A 594.025584485\n","A 602.287804412\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o8wlNnOzIZQD","colab_type":"text"},"source":["This section loads from the files and merges the training datasets with their corresponding labels"]},{"cell_type":"code","metadata":{"id":"hIUQN07nESp8","colab_type":"code","colab":{}},"source":["final_out = torch.load('file2.pt')\n","final_out_targets = torch.load('file_label.pt')\n","final_test = torch.load('test.pt')\n","final_test_tagerts = torch.load('test_label.pt')\n","\n","train_data = []\n","test_data = []\n","for index,(data) in enumerate(final_out):\n","    a=[]\n","    #append the augmented training data and label in a list\n","    a.append(data)\n","    a.append(int(final_out_targets[index]))\n","    #and append that list into the final training set\n","    train_data.append(a)\n","for index,(data) in enumerate(final_test):\n","    a=[]\n","    #append the augmented testing data and label in a list\n","    a.append(data)\n","    a.append(int(final_test_tagerts[index]))\n","    #and append that list into the final testing set\n","    test_data.append(a)\n","\n","train_data_loader = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size, shuffle=True)\n","\n","test_data_loader = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size, shuffle=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6mGFwsOCoof","colab_type":"code","outputId":"149d2787-380f-4cba-c5cc-8bce9a554d87","executionInfo":{"status":"ok","timestamp":1586839234573,"user_tz":240,"elapsed":641581,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","# The composite network which has one custom convolution layer using the subnet and 2 subsequent fully connected layers of 200 nodes each followed by output layer of 10 nodes\n","def create_nn(learning_rate=0.01, epochs=10,\n","              log_interval=10):\n","    class Net(nn.Module):\n","        #Defining the network architecture of 4 fully connected layers, input and output layer inclusive\n","        #Layer 1 size = 56X56 input converted to 28X28 output\n","        #Layer 2 size = 200\n","        #Layer 3 size = 200\n","        #Layer 4 size = 10 (representing the output digit 0 to 9)\n","        def __init__(self):\n","            super(Net, self).__init__()\n","            self.layer1 = nn.Sequential(\n","                nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=2),\n","                nn.ReLU()\n","                ,nn.MaxPool2d(kernel_size=2, stride=2)\n","                )\n","            self.layer2 = nn.Sequential(\n","                nn.Conv2d(10, 10, kernel_size=5, stride=1, padding=2),\n","                nn.ReLU()\n","                ,nn.MaxPool2d(kernel_size=2, stride=2)\n","                )\n","            self.fc1 = nn.Linear(490, 200)\n","            self.fc2 = nn.Linear(200, 200)\n","            self.f7 = nn.Linear(200, 10)\n","\n","        def forward(self, x):\n","            # excempting the subnet from backpropogation\n","            # sending the input 'x' to the subnet for evaluation\n","            # with torch.no_grad():\n","            #     x = custom_conv(x)\n","            if use_cuda and torch.cuda.is_available():\n","              x = x.cuda()\n","            x = self.layer1(x)\n","            x = self.layer2(x)\n","            x = x.reshape(x.size(0), -1)\n","            x = x.reshape(x.size(0), -1)#TODO: Try commenting this and see if it is still needed - YES\n","            #The output of every hidden layer is subject to the relu function as configured in the forward method below\n","            #The final output is subject to log_softmax function as a way to normalize our output\n","            x = F.relu(self.fc1(x))\n","            x = F.relu(self.fc2(x))\n","            x = self.f7(x)\n","            return F.log_softmax(x)\n","\n","    net = Net()\n","    if use_cuda and torch.cuda.is_available():\n","        net.cuda()\n","    print(net)\n","\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n","\n","    # run the main training loop\n","    for epoch in range(epochs):\n","        for batch_idx, (data1, target) in enumerate(train_data_loader):\n","            data1, target = Variable(data1), Variable(target)\n","\n","            if use_cuda and torch.cuda.is_available():\n","                data1 = data1.cuda()\n","                target = target.cuda()\n","            \n","            #This zeroes / resets all the gradients in the model, so that it is ready to go for the next back propagation pass\n","            optimizer.zero_grad()\n","            net_out = net(data1)\n","\n","            #This set of statements runs the backpropogation based on the loss and gradient calculated\n","            loss = criterion(net_out, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch_idx % log_interval == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, batch_idx * len(data1), len(train_data_loader.dataset),\n","                           100. * batch_idx / len(train_data_loader), loss.data))\n","    return net\n","\n","# run a test loop\n","def test_nn():\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_data_loader:\n","        data, target = Variable(data, volatile=True), Variable(target)\n","\n","        if use_cuda and torch.cuda.is_available():\n","            data = data.cuda()\n","            target = target.cuda()\n","        net_out = net(data)\n","        # sum up batch loss\n","        test_loss += criterion(net_out, target).data\n","        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n","        correct += pred.eq(target.data).sum()\n","\n","    test_loss /= len(test_data_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_data_loader.dataset),\n","        100. * correct / len(test_data_loader.dataset)))\n","\n","\n","if __name__ == \"__main__\":\n","    run_opt = 2\n","    if run_opt == 1:\n","        simple_gradient()\n","    elif run_opt == 2:\n","        net = create_nn()\n","        test_nn()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Net(\n","  (layer1): Sequential(\n","    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (0): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc1): Linear(in_features=490, out_features=200, bias=True)\n","  (fc2): Linear(in_features=200, out_features=200, bias=True)\n","  (f7): Linear(in_features=200, out_features=10, bias=True)\n",")\n","Train Epoch: 0 [0/12600 (0%)]\tLoss: 2.370031\n","Train Epoch: 0 [2000/12600 (16%)]\tLoss: 1.949718\n","Train Epoch: 0 [4000/12600 (32%)]\tLoss: 0.722605\n","Train Epoch: 0 [6000/12600 (48%)]\tLoss: 1.639435\n","Train Epoch: 0 [8000/12600 (63%)]\tLoss: 1.296769\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 0 [10000/12600 (79%)]\tLoss: 0.961056\n","Train Epoch: 0 [12000/12600 (95%)]\tLoss: 0.707834\n","Train Epoch: 1 [0/12600 (0%)]\tLoss: 0.700757\n","Train Epoch: 1 [2000/12600 (16%)]\tLoss: 0.678277\n","Train Epoch: 1 [4000/12600 (32%)]\tLoss: 0.699456\n","Train Epoch: 1 [6000/12600 (48%)]\tLoss: 0.687328\n","Train Epoch: 1 [8000/12600 (63%)]\tLoss: 0.667806\n","Train Epoch: 1 [10000/12600 (79%)]\tLoss: 0.648604\n","Train Epoch: 1 [12000/12600 (95%)]\tLoss: 0.659800\n","Train Epoch: 2 [0/12600 (0%)]\tLoss: 0.644006\n","Train Epoch: 2 [2000/12600 (16%)]\tLoss: 0.551897\n","Train Epoch: 2 [4000/12600 (32%)]\tLoss: 0.575472\n","Train Epoch: 2 [6000/12600 (48%)]\tLoss: 0.500388\n","Train Epoch: 2 [8000/12600 (63%)]\tLoss: 0.569587\n","Train Epoch: 2 [10000/12600 (79%)]\tLoss: 0.411882\n","Train Epoch: 2 [12000/12600 (95%)]\tLoss: 0.367343\n","Train Epoch: 3 [0/12600 (0%)]\tLoss: 0.327661\n","Train Epoch: 3 [2000/12600 (16%)]\tLoss: 0.320801\n","Train Epoch: 3 [4000/12600 (32%)]\tLoss: 0.407250\n","Train Epoch: 3 [6000/12600 (48%)]\tLoss: 0.258225\n","Train Epoch: 3 [8000/12600 (63%)]\tLoss: 0.354620\n","Train Epoch: 3 [10000/12600 (79%)]\tLoss: 0.243204\n","Train Epoch: 3 [12000/12600 (95%)]\tLoss: 0.208229\n","Train Epoch: 4 [0/12600 (0%)]\tLoss: 0.225804\n","Train Epoch: 4 [2000/12600 (16%)]\tLoss: 0.249286\n","Train Epoch: 4 [4000/12600 (32%)]\tLoss: 0.185792\n","Train Epoch: 4 [6000/12600 (48%)]\tLoss: 0.183549\n","Train Epoch: 4 [8000/12600 (63%)]\tLoss: 0.126483\n","Train Epoch: 4 [10000/12600 (79%)]\tLoss: 0.365758\n","Train Epoch: 4 [12000/12600 (95%)]\tLoss: 0.246416\n","Train Epoch: 5 [0/12600 (0%)]\tLoss: 0.197137\n","Train Epoch: 5 [2000/12600 (16%)]\tLoss: 0.174644\n","Train Epoch: 5 [4000/12600 (32%)]\tLoss: 0.149181\n","Train Epoch: 5 [6000/12600 (48%)]\tLoss: 0.125580\n","Train Epoch: 5 [8000/12600 (63%)]\tLoss: 0.124660\n","Train Epoch: 5 [10000/12600 (79%)]\tLoss: 0.185926\n","Train Epoch: 5 [12000/12600 (95%)]\tLoss: 0.154977\n","Train Epoch: 6 [0/12600 (0%)]\tLoss: 0.178889\n","Train Epoch: 6 [2000/12600 (16%)]\tLoss: 0.113165\n","Train Epoch: 6 [4000/12600 (32%)]\tLoss: 0.140817\n","Train Epoch: 6 [6000/12600 (48%)]\tLoss: 0.130596\n","Train Epoch: 6 [8000/12600 (63%)]\tLoss: 0.109749\n","Train Epoch: 6 [10000/12600 (79%)]\tLoss: 0.245858\n","Train Epoch: 6 [12000/12600 (95%)]\tLoss: 0.213041\n","Train Epoch: 7 [0/12600 (0%)]\tLoss: 0.091235\n","Train Epoch: 7 [2000/12600 (16%)]\tLoss: 0.155309\n","Train Epoch: 7 [4000/12600 (32%)]\tLoss: 0.110856\n","Train Epoch: 7 [6000/12600 (48%)]\tLoss: 0.140359\n","Train Epoch: 7 [8000/12600 (63%)]\tLoss: 0.107529\n","Train Epoch: 7 [10000/12600 (79%)]\tLoss: 0.128490\n","Train Epoch: 7 [12000/12600 (95%)]\tLoss: 0.075618\n","Train Epoch: 8 [0/12600 (0%)]\tLoss: 0.070169\n","Train Epoch: 8 [2000/12600 (16%)]\tLoss: 0.149766\n","Train Epoch: 8 [4000/12600 (32%)]\tLoss: 0.061353\n","Train Epoch: 8 [6000/12600 (48%)]\tLoss: 0.114263\n","Train Epoch: 8 [8000/12600 (63%)]\tLoss: 0.131171\n","Train Epoch: 8 [10000/12600 (79%)]\tLoss: 0.108456\n","Train Epoch: 8 [12000/12600 (95%)]\tLoss: 0.049858\n","Train Epoch: 9 [0/12600 (0%)]\tLoss: 0.077249\n","Train Epoch: 9 [2000/12600 (16%)]\tLoss: 0.097332\n","Train Epoch: 9 [4000/12600 (32%)]\tLoss: 0.123910\n","Train Epoch: 9 [6000/12600 (48%)]\tLoss: 0.100758\n","Train Epoch: 9 [8000/12600 (63%)]\tLoss: 0.047075\n","Train Epoch: 9 [10000/12600 (79%)]\tLoss: 0.045455\n","Train Epoch: 9 [12000/12600 (95%)]\tLoss: 0.037425\n","\n","Test set: Average loss: 0.0003, Accuracy: 1967/2000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6NfLZkDtjCVF","colab_type":"code","colab":{}},"source":["class Net3(nn.Module):\n","    def __init__(self):\n","        super(Net3, self).__init__()\n","\n","    def forward(self, x):\n","        if use_cuda and torch.cuda.is_available():\n","          x = x.cuda()\n","        x = custom_conv(x)\n","        x = net(x)\n","        return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S42pT1vID2KU","colab_type":"text"},"source":["# Final testing Section\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"M6JzUbnCLaCZ","colab_type":"code","outputId":"730e8b54-a9b5-47a1-d461-34a23de32ff1","executionInfo":{"status":"ok","timestamp":1586839318119,"user_tz":240,"elapsed":725113,"user":{"displayName":"Gurman Singh","photoUrl":"","userId":"15595727080380430111"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["filtered_test1 = []\n","# print(data)\n","for data in enumerate(mnist):\n","    if(data[1][1] == 1 or data[1][1] == 0):\n","        # print((data[0],data[1]))\n","        filtered_test1.append(list(data[1]))\n","\n","#Readjusting the data to a size of multiple of 'batch_size' by slicing\n","filtered_test1 = filtered_test1[0:-(len(filtered_test1)%batch_size)]\n","\n","#storing the filtered data in the torch's dataLoader with batch size and shuffle capabilities\n","#The data loader provides easier management of the data with automatic facilities like shuffling data and dividing it into batches.\n","test_loader1 = torch.utils.data.DataLoader(\n","    filtered_test1,\n","    batch_size=batch_size, shuffle=True)\n","\n","test_loss = 0\n","correct = 0\n","net3 = Net3()\n","for data, target in test_loader1:\n","    data, target = Variable(data, volatile=True), Variable(target)\n","\n","    temp = torch.as_tensor(np.zeros((200, 1, 28*2, 28*2))).float()\n","    for i,(image) in enumerate(data):\n","        rndx = randrange(29)\n","        rndy = randrange(29)\n","        temp[i][0] = shuffle(rndx,rndy,image)\n","    data = temp\n","\n","    if use_cuda and torch.cuda.is_available():\n","        data = data.cuda()\n","        target = target.cuda()\n","    data = data.view(-1,56,56)\n","\n","    net_out = net3(data)\n","\n","    # sum up batch loss\n","    test_loss += criterion(net_out, target).data\n","    pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n","    correct += pred.eq(target.data).sum()\n","\n","test_loss /= len(test_loader1.dataset)\n","print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(test_loader1.dataset),\n","    100. * correct / len(test_loader1.dataset)))\n","\n","# torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["A 614.084824857\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["A 622.392105865\n","A 630.774633891\n","A 639.16805467\n","A 647.36544299\n","A 655.524775051\n","A 663.693249375\n","A 671.837056253\n","A 679.949556379\n","A 688.029177836\n","\n","Test set: Average loss: 0.0003, Accuracy: 1953/2000 (98%)\n","\n"],"name":"stdout"}]}]}