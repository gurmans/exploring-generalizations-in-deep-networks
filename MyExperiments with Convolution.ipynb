{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MyExperiments with Convolution.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"on3sHGUjSUkp","colab_type":"text"},"source":["#Convolution for Augmentated data\n","\n","The MNIST data is augmented for better understanding of convolution and its working. For this we use the 28X28 image and add it to an array of zeroes of size 56X56. For details refer to \"Shuffle\" method.\n","So after augmentation, our 28X28 image can be located anywhere on the 56X56 grid. And we learn what configuration and intuitive factors help the convolutional neural network identify the digit on the input image."]},{"cell_type":"code","metadata":{"id":"Q6mGFwsOCoof","colab_type":"code","colab":{}},"source":["from random import randrange\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","batch_size=200\n","criterion = nn.NLLLoss()\n","\n","#Download the training data and apply transformations\n","#to transform the MNIST data into tensor datatype and normalize the values\n","#store the data in the torch's dataLoader with batch size and shuffle capabilities\n","#The data loader provides easier management of the data with automatic facilities like shuffling data and dividing it into batches.\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, \n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True)\n","use_cuda = True\n","\n","# rndx and rndy determine the position of the 28X28 'image' in the 56X56 grid(here stored in 'a')\n","def shuffle(rndx,rndy,image):\n","    a = np.zeros((56,56))\n","    image = image.view(-1, 28)\n","    # Adding the 'image' to the part of 'a' sliced from 'rndx', 'rndy'\n","    a[rndx:28+rndx,rndy:28+rndy]+=np.array(image)\n","    return torch.as_tensor(a).float()\n","\n","flag = False\n","# The network which has two layers of convolution and 2 subsequent fully connected layers of 200 nodes each followed by output layer of 10 nodes\n","def create_nn(learning_rate=0.01, epochs=10,\n","              log_interval=10):\n","    class Net(nn.Module):\n","        #Defining the network architecture, input and output layer inclusive\n","        #Layer 1 size = 28X28 size convolution filetr(or kernel) of stride 1, followed by pooling of size 2 stride 2, converted to 15 14X14 output channels\n","        #Layer 2 size = 4X4 size convolution filetr(or kernel) of stride 1, padding 3, followed by pooling of size 2 stride 2, converted to 32 8X8 output channels\n","        #Layer 3 size = 200\n","        #Layer 4 size = 200\n","        #Layer 5 size = 10 (representing the output digit 0 to 9)\n","        def __init__(self):\n","            super(Net, self).__init__()\n","            self.layer1 = nn.Sequential(\n","                nn.Conv2d(1, 15, kernel_size=28, stride=1, padding=0),\n","                nn.ReLU()\n","                ,nn.MaxPool2d(kernel_size=2, stride=2)\n","                )\n","            self.layer2 = nn.Sequential(\n","                nn.Conv2d(15, 32, kernel_size=4, stride=1, padding=3),\n","                nn.ReLU()\n","                ,nn.MaxPool2d(kernel_size=2, stride=2)\n","                )\n","            self.drop_out = nn.Dropout()\n"," \n","            #self.fc1 = nn.Linear(28 * 28 *4, 200)\n","            self.fc1 = nn.Linear(2048, 200)\n","            self.fc2 = nn.Linear(200, 200)\n","            self.f7 = nn.Linear(200, 10)\n","\n","        #The output of every hidden layer is subject to the relu function as configured in the forward method below\n","        #The final output is subject to log_softmax function as a way to normalize our output\n","        def forward(self, x):\n","            x = self.layer1(x)\n","            if flag:\n","              img = x\n","              plt.imshow(img.cpu().detach().numpy()[0][0])\n","              plt.show()\n","            x = self.layer2(x)\n","            x = x.reshape(x.size(0), -1)\n","            x = self.drop_out(x)\n","            x = F.relu(self.fc1(x))\n","            x = F.relu(self.fc2(x))\n","            x = self.f7(x)\n","            return F.log_softmax(x)\n","\n","    net = Net()\n","    if use_cuda and torch.cuda.is_available():\n","        net.cuda()\n","    print(net)\n","\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n","\n","    # run the main training loop\n","    for epoch in range(epochs):\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            data, target = Variable(data), Variable(target)\n","            # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n","            temp = torch.as_tensor(np.zeros((200, 1, 28*2, 28*2))).float()\n","            for i,(image) in enumerate(data):\n","                rndx = randrange(29)\n","                rndy = randrange(29)\n","                temp[i][0] = shuffle(rndx,rndy,image)\n","            data = temp\n","            if use_cuda and torch.cuda.is_available():\n","                data = data.cuda()\n","                target = target.cuda()\n","            \n","            optimizer.zero_grad()\n","            net_out = net(data)\n","            loss = criterion(net_out, target)\n","            loss.backward()\n","            optimizer.step()\n","            if batch_idx % log_interval == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, batch_idx * len(data), len(train_loader.dataset),\n","                           100. * batch_idx / len(train_loader), loss.data))\n","    return net\n","\n","    # run a test loop\n","def test_nn():\n","    test_loss = 0\n","    correct = 0\n","    flag = True\n","    for data, target in test_loader:\n","        data, target = Variable(data, volatile=True), Variable(target)\n","\n","        temp = torch.as_tensor(np.zeros((200, 1, 28*2, 28*2))).float()\n","        for i,(image) in enumerate(data):\n","            rndx = 0#randrange(29)\n","            rndy = 0#randrange(29)\n","            temp[i][0] = shuffle(rndx,rndy,image)\n","        data = temp\n","\n","        if use_cuda and torch.cuda.is_available():\n","            data = data.cuda()\n","            target = target.cuda()\n","        net_out = net(data)\n","        # sum up batch loss\n","        test_loss += criterion(net_out, target).data\n","        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n","        correct += pred.eq(target.data).sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","\n","if __name__ == \"__main__\":\n","    run_opt = 2\n","    if run_opt == 1:\n","        simple_gradient()\n","    elif run_opt == 2:\n","        net = create_nn()\n","        test_nn()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6JzUbnCLaCZ","colab_type":"code","colab":{}},"source":["    test_loss = 0\n","    correct = 0\n","    flag = True\n","    for data, target in test_loader:\n","        data, target = Variable(data, volatile=True), Variable(target)\n","\n","        temp = torch.as_tensor(np.zeros((200, 1, 28*2, 28*2))).float()\n","        for i,(image) in enumerate(data):\n","            rndx = randrange(29)\n","            rndy = randrange(29)\n","            temp[i][0] = shuffle(rndx,rndy,image)\n","        data = temp\n","\n","        if use_cuda and torch.cuda.is_available():\n","            data = data.cuda()\n","            target = target.cuda()\n","        net_out = net(data)\n","        # sum up batch loss\n","        test_loss += criterion(net_out, target).data\n","        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n","        correct += pred.eq(target.data).sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","# torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"],"execution_count":0,"outputs":[]}]}